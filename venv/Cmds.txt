1) First create virtual env using python -m venv venv (done)
2) Shift to venv by 'source venv/Scripts/activate'
3) Install dbt core: python -m pip install dbt-core
4) Install the necessary datawarehouse: pip install dbt-snowflake

Snowflake:
Each worksheet on snowflake has a role, warehouse and a schema to be defined
then give usage access n warehouse and all access on database. Proceed to use created role and create a scehema in the database

5) Then I ran 'dbt init' to initialize The dbt init command initializes a new dbt project.
It sets up the directory structure and configuration files needed to start building and managing your data transformations using dbt.

6) I created two new tables and views in my models and installed packages in packge.yml using 'dbt deps'

7) I am unblt  connect to snowflake so trying to debug: problem was i used the whole url in locator, just use the name of locator
-- To view your profiles.yml file, run:
open /Users/rojan/.dbt

8) to run sql scripts in staging: use dbt run
- for specific script use dbt run -s filename.sql // -s indicate sstaging

-- succesly i ran my staging scits and I see them as views ins nowflake warehouse

9) Now staging tables are 1:1 with src tave. I need to rdate aggregations and metrics rom staging tbales to et fact tables. These tables has foreign keys for each ofthe associated dimenions

10) ENsure you are running the tables u r referencing first before u run th ones in marts

11) Macro fns are good way to reuse business logic across multiple models. FOllow Jinja template.
